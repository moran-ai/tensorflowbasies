{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MINST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MINST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MINST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MINST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# coding:gbk\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"MINST_data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0413 16:40:37.235875  5516 deprecation.py:323] From <ipython-input-3-c15f8840c474>:35: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter(训练次数):0 ,Testing Accuracy(正确率):0.825\n"
     ]
    }
   ],
   "source": [
    "# 每个批次的大小\n",
    "batch_size = 100\n",
    "\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "# 定义input的命名空间\n",
    "with tf.name_scope(\"input\"):\n",
    "    # 定义两个placeholder\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name=\"x-input\")\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name=\"y-input\")\n",
    "\n",
    "\n",
    "# 定义命名空间\n",
    "with tf.name_scope(\"layer\"):\n",
    "    # 创建一个简单的神经网络\n",
    "    # 定义权值的命名空间\n",
    "    with tf.name_scope(\"wights\"):\n",
    "        w = tf.Variable(tf.zeros([784, 10]), name=\"W\")\n",
    "    # 定义偏置值的命名空间\n",
    "    with tf.name_scope(\"biases\"):\n",
    "        b = tf.Variable(tf.zeros(10), name=\"b\")\n",
    "    # 定义wx_plus_b命名空间\n",
    "    with tf.name_scope(\"wx_plus_b\"):\n",
    "        wx_plus_b = tf.matmul(x, w) + b\n",
    "# 预测值\n",
    "# prediction = tf.nn.softmax(tf.matmul(x, w)+b)\n",
    "    # 定义softmax命名空间\n",
    "    with tf.name_scope(\"softmax\"):\n",
    "        prediction = tf.nn.softmax(wx_plus_b)\n",
    "\n",
    "# 二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "    with tf.name_scope('train'):\n",
    "        # 使用梯度下降法\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 函数equal比较两个参数的大小，一样为True， 不一样为False\n",
    "# 找出真实值的最大值标签和预测值的最大值标签\n",
    "# 结果存放在一个布尔值列表中\n",
    "# argmax函数返回一维张量中最大值所在的位置\n",
    "# 真实值与预测值的对比\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    with tf.name_scope(\"correct_prediction\"):\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        # 求准确率\n",
    "        # cast函数将correct_prediction由布尔类型转换为浮点型\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# 构建会话\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # \"logs/\":路径，sess.graph：存放的文件\n",
    "    # writer = tf.summary.FileWriter(\"logS/\", sess.graph)\n",
    "    writer = tf.summary.FileWriter(\"los/\", sess.graph)\n",
    "    # 所有图片训练1次\n",
    "    for epoch in range(1):\n",
    "        # 训练n_batch次\n",
    "        for batch in range(n_batch):\n",
    "            # 图片的的信心保存在batch_xs中，图片的标签保存在batch_ys中\n",
    "            # 第一次是0-100，第二次是100-200，第三次是200-300，依次类推\n",
    "            # 每一个批次是100\n",
    "            # 获得批次的数据\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # 对获得的数据进行训练,直到把所有的图片训练一次\n",
    "            sess.run(train_step, feed_dict={x: batch_xs, y : batch_ys})\n",
    "\n",
    "        # 测试准确率\n",
    "        acc = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "        # 打印训练次数和每一次的准确率\n",
    "        print(\"Iter(训练次数):\" + str(epoch) + \" ,Testing Accuracy(正确率):\" + str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MINST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MINST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MINST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MINST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter(训练次数):0 ,Testing Accuracy(正确率):0.8333\n",
      "Iter(训练次数):1 ,Testing Accuracy(正确率):0.8941\n",
      "Iter(训练次数):2 ,Testing Accuracy(正确率):0.9021\n",
      "Iter(训练次数):3 ,Testing Accuracy(正确率):0.9067\n",
      "Iter(训练次数):4 ,Testing Accuracy(正确率):0.9086\n",
      "Iter(训练次数):5 ,Testing Accuracy(正确率):0.9103\n",
      "Iter(训练次数):6 ,Testing Accuracy(正确率):0.912\n",
      "Iter(训练次数):7 ,Testing Accuracy(正确率):0.9144\n",
      "Iter(训练次数):8 ,Testing Accuracy(正确率):0.9152\n",
      "Iter(训练次数):9 ,Testing Accuracy(正确率):0.9169\n",
      "Iter(训练次数):10 ,Testing Accuracy(正确率):0.9168\n",
      "Iter(训练次数):11 ,Testing Accuracy(正确率):0.9194\n",
      "Iter(训练次数):12 ,Testing Accuracy(正确率):0.9183\n",
      "Iter(训练次数):13 ,Testing Accuracy(正确率):0.9196\n",
      "Iter(训练次数):14 ,Testing Accuracy(正确率):0.9203\n",
      "Iter(训练次数):15 ,Testing Accuracy(正确率):0.9205\n",
      "Iter(训练次数):16 ,Testing Accuracy(正确率):0.9215\n",
      "Iter(训练次数):17 ,Testing Accuracy(正确率):0.9209\n",
      "Iter(训练次数):18 ,Testing Accuracy(正确率):0.9211\n",
      "Iter(训练次数):19 ,Testing Accuracy(正确率):0.9208\n",
      "Iter(训练次数):20 ,Testing Accuracy(正确率):0.922\n",
      "Iter(训练次数):21 ,Testing Accuracy(正确率):0.9218\n",
      "Iter(训练次数):22 ,Testing Accuracy(正确率):0.9221\n",
      "Iter(训练次数):23 ,Testing Accuracy(正确率):0.923\n",
      "Iter(训练次数):24 ,Testing Accuracy(正确率):0.9237\n",
      "Iter(训练次数):25 ,Testing Accuracy(正确率):0.9233\n",
      "Iter(训练次数):26 ,Testing Accuracy(正确率):0.9234\n",
      "Iter(训练次数):27 ,Testing Accuracy(正确率):0.9236\n",
      "Iter(训练次数):28 ,Testing Accuracy(正确率):0.924\n",
      "Iter(训练次数):29 ,Testing Accuracy(正确率):0.9243\n",
      "Iter(训练次数):30 ,Testing Accuracy(正确率):0.9243\n",
      "Iter(训练次数):31 ,Testing Accuracy(正确率):0.9247\n",
      "Iter(训练次数):32 ,Testing Accuracy(正确率):0.9238\n",
      "Iter(训练次数):33 ,Testing Accuracy(正确率):0.9246\n",
      "Iter(训练次数):34 ,Testing Accuracy(正确率):0.9243\n",
      "Iter(训练次数):35 ,Testing Accuracy(正确率):0.9255\n",
      "Iter(训练次数):36 ,Testing Accuracy(正确率):0.9249\n",
      "Iter(训练次数):37 ,Testing Accuracy(正确率):0.9249\n",
      "Iter(训练次数):38 ,Testing Accuracy(正确率):0.9256\n",
      "Iter(训练次数):39 ,Testing Accuracy(正确率):0.9263\n",
      "Iter(训练次数):40 ,Testing Accuracy(正确率):0.926\n",
      "Iter(训练次数):41 ,Testing Accuracy(正确率):0.9255\n",
      "Iter(训练次数):42 ,Testing Accuracy(正确率):0.9263\n",
      "Iter(训练次数):43 ,Testing Accuracy(正确率):0.9259\n",
      "Iter(训练次数):44 ,Testing Accuracy(正确率):0.9266\n",
      "Iter(训练次数):45 ,Testing Accuracy(正确率):0.9263\n",
      "Iter(训练次数):46 ,Testing Accuracy(正确率):0.9268\n",
      "Iter(训练次数):47 ,Testing Accuracy(正确率):0.9265\n",
      "Iter(训练次数):48 ,Testing Accuracy(正确率):0.9267\n",
      "Iter(训练次数):49 ,Testing Accuracy(正确率):0.9264\n",
      "Iter(训练次数):50 ,Testing Accuracy(正确率):0.927\n"
     ]
    }
   ],
   "source": [
    "# coding:gbk\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"MINST_data\", one_hot=True)\n",
    "\n",
    "# 每个批次的大小\n",
    "batch_size = 100\n",
    "\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "# 参数概要\n",
    "# 定义一个计算各类值的函数\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope(\"summaries\"):\n",
    "        mean =  tf.reduce_mean(var)\n",
    "        # tf.summary.scalar参数:第一个参数为名字，第二个参数为所求的值\n",
    "        tf.summary.scalar(\"mean\", mean)  # 平均值\n",
    "        with tf.name_scope(\"stddev\"):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var-mean)))\n",
    "            tf.summary.scalar(\"stddev\", stddev)  # 标准差\n",
    "            tf.summary.scalar(\"max\", tf.reduce_max(var))  # 最大值\n",
    "            tf.summary.scalar(\"min\", tf.reduce_min(var))  # 最小值\n",
    "            tf.summary.histogram(\"histogram\", var)   # 直方图\n",
    "\n",
    "# 定义input的命名空间\n",
    "with tf.name_scope(\"input\"):\n",
    "    # 定义两个placeholder\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name=\"x-input\")\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name=\"y-input\")\n",
    "\n",
    "\n",
    "# 定义命名空间\n",
    "with tf.name_scope(\"layer\"):\n",
    "    # 创建一个简单的神经网络\n",
    "    # 定义权值的命名空间\n",
    "    with tf.name_scope(\"wights\"):\n",
    "        w = tf.Variable(tf.zeros([784, 10]), name=\"W\")\n",
    "        # 分析权值的变化\n",
    "        variable_summaries(w)\n",
    "    # 定义偏置值的命名空间\n",
    "    with tf.name_scope(\"biases\"):\n",
    "        b = tf.Variable(tf.zeros(10), name=\"b\")\n",
    "        # 分析偏置值的变化\n",
    "        variable_summaries(b)\n",
    "    # 定义wx_plus_b命名空间\n",
    "    with tf.name_scope(\"wx_plus_b\"):\n",
    "        wx_plus_b = tf.matmul(x, w) + b\n",
    "# 预测值\n",
    "# prediction = tf.nn.softmax(tf.matmul(x, w)+b)\n",
    "    # 定义softmax命名空间\n",
    "    with tf.name_scope(\"softmax\"):\n",
    "        prediction = tf.nn.softmax(wx_plus_b)\n",
    "\n",
    "# 二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    with tf.name_scope('train'):\n",
    "        # 使用梯度下降法\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 函数equal比较两个参数的大小，一样为True， 不一样为False\n",
    "# 找出真实值的最大值标签和预测值的最大值标签\n",
    "# 结果存放在一个布尔值列表中\n",
    "# argmax函数返回一维张量中最大值所在的位置\n",
    "# 真实值与预测值的对比\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    with tf.name_scope(\"correct_prediction\"):\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        # 求准确率\n",
    "        # cast函数将correct_prediction由布尔类型转换为浮点型\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        # 记录准确率的变化\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# 合并所有的summary\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "# 构建会话\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # \"logs/\":路径，sess.graph：存放的文件\n",
    "    # writer = tf.summary.FileWriter(\"logS/\", sess.graph)\n",
    "    writer = tf.summary.FileWriter(\"los/\", sess.graph)\n",
    "    # 所有图片训练50次\n",
    "    for epoch in range(51):\n",
    "        # 训练n_batch次\n",
    "        for batch in range(n_batch):\n",
    "            # 图片的的信心保存在batch_xs中，图片的标签保存在batch_ys中\n",
    "            # 第一次是0-100，第二次是100-200，第三次是200-300，依次类推\n",
    "            # 每一个批次是100\n",
    "            # 获得批次的数据\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # 对获得的数据进行训练,直到把所有的图片训练一次\n",
    "            # [merged,train_step]训练时同时统计权值、偏置值、loss的变化\n",
    "            # 统计完成后有返回值，返回值为summary,_\n",
    "            summary,_ = sess.run([merged, train_step], feed_dict={x: batch_xs, y : batch_ys})\n",
    "        # 每执行一次epoch(次数),将summary写入指定的文件路径中\n",
    "        writer.add_summary(summary, epoch)\n",
    "        # 测试准确率\n",
    "        acc = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "        # 打印训练次数和每一次的准确率\n",
    "        print(\"Iter(训练次数):\" + str(epoch) + \" ,Testing Accuracy(正确率):\" + str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding:gbk\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "# 每个批次的大小\n",
    "# batch_size = 100\n",
    "# 运行次数\n",
    "max_steps = 1001\n",
    "\n",
    "# 图片数量\n",
    "image_num = 3000\n",
    "\n",
    "# 文件路径\n",
    "DIR = \"C:\\\\Users\\\\20622\\\\Tensorflow深度学习\\\\\"\n",
    "# 计算一共有多少个批次\n",
    "# n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "# 定义会话\n",
    "sess = tf.Session()\n",
    "\n",
    "# 载入图片\n",
    "embedding = tf.Variable(tf.stack(mnist.test.images[:image_num]), trainable=False, name=\"embedding\")\n",
    "\n",
    "# 参数概要\n",
    "# 定义一个计算各类值的函数\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope(\"summaries\"):\n",
    "        mean =  tf.reduce_mean(var)\n",
    "        # tf.summary.scalar参数:第一个参数为名字，第二个参数为所求的值\n",
    "        tf.summary.scalar(\"mean\", mean)  # 平均值\n",
    "        with tf.name_scope(\"stddev\"):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var-mean)))\n",
    "            tf.summary.scalar(\"stddev\", stddev)  # 标准差\n",
    "            tf.summary.scalar(\"max\", tf.reduce_max(var))  # 最大值\n",
    "            tf.summary.scalar(\"min\", tf.reduce_min(var))  # 最小值\n",
    "            tf.summary.histogram(\"histogram\", var)   # 直方图\n",
    "\n",
    "# 定义input的命名空间\n",
    "with tf.name_scope(\"input\"):\n",
    "    # 定义两个placeholder\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name=\"x-input\")\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name=\"y-input\")\n",
    "\n",
    "# 显示图片\n",
    "with tf.name_scope(\"input_reshape\"):\n",
    "    # 将x的形状转化为[-1, 28, 28, 1]的形状，-1代表不确定值，28行28列， 维度为1\n",
    "    image_shaped_input = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    # 10表示10张图片\n",
    "    tf.summary.image(\"input\", image_shaped_input, 10)\n",
    "\n",
    "# 定义命名空间\n",
    "with tf.name_scope(\"layer\"):\n",
    "    # 创建一个简单的神经网络\n",
    "    # 定义权值的命名空间\n",
    "    with tf.name_scope(\"wights\"):\n",
    "        w = tf.Variable(tf.zeros([784, 10]), name=\"W\")\n",
    "        # 分析权值的变化\n",
    "        variable_summaries(w)\n",
    "    # 定义偏置值的命名空间\n",
    "    with tf.name_scope(\"biases\"):\n",
    "        b = tf.Variable(tf.zeros(10), name=\"b\")\n",
    "        # 分析偏置值的变化\n",
    "        variable_summaries(b)\n",
    "    # 定义wx_plus_b命名空间\n",
    "    with tf.name_scope(\"wx_plus_b\"):\n",
    "        wx_plus_b = tf.matmul(x, w) + b\n",
    "# 预测值\n",
    "# prediction = tf.nn.softmax(tf.matmul(x, w)+b)\n",
    "    # 定义softmax命名空间\n",
    "    with tf.name_scope(\"softmax\"):\n",
    "        prediction = tf.nn.softmax(wx_plus_b)\n",
    "\n",
    "# 二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "with tf.name_scope('loss'):\n",
    "    # 交叉熵代价函数\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    with tf.name_scope('train'):\n",
    "        # 使用梯度下降法\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# 函数equal比较两个参数的大小，一样为True， 不一样为False\n",
    "# 找出真实值的最大值标签和预测值的最大值标签\n",
    "# 结果存放在一个布尔值列表中\n",
    "# argmax函数返回一维张量中最大值所在的位置\n",
    "# 真实值与预测值的对比\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    with tf.name_scope(\"correct_prediction\"):\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        # 求准确率\n",
    "        # cast函数将correct_prediction由布尔类型转换为浮点型\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        # 记录准确率的变化\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# 产生metadata文件\n",
    "# 如果有这个文件， 就会删除这个对应的文件\n",
    "if tf.gfile.Exists(DIR+\"projector/projector/metadata.tsv\"):\n",
    "    tf.gfile.DeleteRecursively(DIR+\"projector/projector/metadata.tsv\")\n",
    "    # tf.gfile.remove(DIR + \"projector/projector/metadata.tsv\")\n",
    "\n",
    "# 没有这个文件，就会生成对应的文件\n",
    "with open(DIR + \"projector/projector/metadata.tsv\", \"w\") as f:\n",
    "    # 求出标签最大值所在的位置\n",
    "    labels = sess.run(tf.argmax(mnist.test.labels[:], 1))\n",
    "    # 循环3000次\n",
    "    for i in range(image_num):\n",
    "        # 将每次循环的结果写入文件中\n",
    "        f.write(str(labels[i]) + \"\\n\")\n",
    "\n",
    "# 合并所有的summary\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "projector_writer = tf.summary.FileWriter(DIR+\"projector/projector\", sess.graph)\n",
    "\n",
    "# 保存网络模型\n",
    "saver = tf.train.Saver()\n",
    "# 配置项\n",
    "config = projector.ProjectorConfig()\n",
    "embed = config.embeddings.add()\n",
    "\n",
    "# embedding的名字赋给embed.tensor\n",
    "embed.tensor_name = embedding.name\n",
    "\n",
    "# 文件路径\n",
    "embed.metadata_path = DIR + \"projector/projector/metadata.tsv\"\n",
    "\n",
    "# 图片路径\n",
    "embed.sprite.image_path = DIR +\"projector/data/mnist_10k_sprite.png\"\n",
    "\n",
    "# 切分为28x28的像素\n",
    "embed.sprite.single_image_dim.extend([28, 28])\n",
    "\n",
    "# 进入可视化的工具\n",
    "projector.visualize_embeddings(projector_writer, config)\n",
    "\n",
    "for i in range(max_steps):\n",
    "    # 每个批次100个样本\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "\n",
    "    # 配置项\n",
    "    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "    run_metadata = tf.RunMetadata()\n",
    "\n",
    "    summary,_ = sess.run([merged, train_step], feed_dict={x:batch_xs, y:batch_ys}, options=run_options, run_metadata=run_metadata)\n",
    "    projector_writer.add_run_metadata(run_metadata, 'step%03d' % i)\n",
    "    projector_writer.add_summary(summary, i)\n",
    "\n",
    "    # 每训练100次100次， 打印准确率\n",
    "    if i % 100 == 0:\n",
    "        acc = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "        print(\"Iter\" + str(i) + \", Testing Accuracy= \" + str(acc))\n",
    "\n",
    "# 保存训练好的模型\n",
    "saver.save(sess, DIR + 'projector/projector/a_model.ckpt', global_step=max_steps)\n",
    "projector_writer.close()\n",
    "sess.close()\n",
    "\n",
    "#\n",
    "# # 构建会话\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "#     # \"logs/\":路径，sess.graph：存放的文件\n",
    "#     # writer = tf.summary.FileWriter(\"logS/\", sess.graph)\n",
    "#     writer = tf.summary.FileWriter(\"los/\", sess.graph)\n",
    "#     # 所有图片训练50次\n",
    "#     for epoch in range(51):\n",
    "#         # 训练n_batch次\n",
    "#         for batch in range(n_batch):\n",
    "#             # 图片的的信心保存在batch_xs中，图片的标签保存在batch_ys中\n",
    "#             # 第一次是0-100，第二次是100-200，第三次是200-300，依次类推\n",
    "#             # 每一个批次是100\n",
    "#             # 获得批次的数据\n",
    "#             batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "#             # 对获得的数据进行训练,直到把所有的图片训练一次\n",
    "#             # [merged,train_step]训练时同时统计权值、偏置值、loss的变化\n",
    "#             # 统计完成后有返回值，返回值为summary,_\n",
    "#             summary,_ = sess.run([merged, train_step], feed_dict={x: batch_xs, y : batch_ys})\n",
    "#         # 每执行一次epoch(次数),将summary写入指定的文件路径中\n",
    "#         writer.add_summary(summary, epoch)\n",
    "#         # 测试准确率\n",
    "#         acc = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "#         # 打印训练次数和每一次的准确率\n",
    "#         print(\"Iter(训练次数):\" + str(epoch) + \" ,Testing Accuracy(正确率):\" + str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
